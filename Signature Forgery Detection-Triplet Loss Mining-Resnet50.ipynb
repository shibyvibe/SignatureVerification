{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color: red;\">TODO </b>\n",
    "1) Add signatures from dataset1 to dataset2 mainly related to background color <br>\n",
    "2) Understand how to setup tensorflow GPU. Currently using Tensorflow CPU\n",
    "\n",
    "<p style=\"color: red;\">\n",
    "Tensor flow install error\n",
    "\n",
    "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
    "Successfully built wrapt\n",
    "ERROR: catboost 0.24.4 requires plotly, which is not installed.\n",
    "ERROR: tensorflow 1.15.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\n",
    "ERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.4.1 which is incompatible.\n",
    "ERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.4.0 which is incompatible.\n",
    "ERROR: tensorflow-gpu 1.15.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\n",
    "ERROR: tensorflow-gpu 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.4.1 which is incompatible.\n",
    "ERROR: tensorflow-gpu 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.4.0 which is incompatible.\n",
    "ERROR: astroid 2.3.3 has requirement wrapt==1.11.*, but you'll have wrapt 1.12.1 which is incompatible.\n",
    "Installing collected packages: six, absl-py, gast, grpcio, numpy, oauthlib, requests-oauthlib, rsa, cachetools, google-auth, google-auth-oauthlib, tensorboard-plugin-wit, wheel, tensorboard, wrapt, typing-extensions, keras-preprocessing, astunparse, opt-einsum, tensorflow-estimator, flatbuffers, tensorflow-cpu\n",
    "  Attempting uninstall: six\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tuning </b><p>\n",
    "To try\n",
    "* _compute_loss_sq change margin from 0.0 to 0.1   8/3 - Trying (need to retrain)\n",
    "* Use the same loss function in test as used in training.  8/3 - Trying\n",
    "* Try MXNet is faster than tensorflow.\n",
    "\n",
    "* Add a custom layer which included the forgery decision to determine the weights (maybe use a MixMaxScaler to maximize the diff range)\n",
    "* Recalculate all the weights for ResNet50\n",
    "* Try a VGG16 with triplet loss mining.\n",
    "* Build a custom layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import applications  ##Tensor flow version used 2.4.1\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDimensions = (224,224,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Utility functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(filename):\n",
    "    \"\"\"\n",
    "    Load the specified file as a JPEG image, preprocess it and\n",
    "    resize it to the target shape.\n",
    "    \"\"\"\n",
    "\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_png(image_string, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, imageDimensions[:-1])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_triplets_train( anchor, positive, negative):\n",
    "    \"\"\"\n",
    "    Given the filenames corresponding to the three images, load and\n",
    "    preprocess them.\n",
    "    \"\"\"\n",
    "    print(\">>> Anchor\", anchor)\n",
    "\n",
    "    return (\n",
    "        preprocess_image(anchor),\n",
    "        preprocess_image(positive),\n",
    "        preprocess_image(negative),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_triplets(personId, anchor, positive, negative, isGenuine, anchor_path, positive_path, negative_path):\n",
    "    \"\"\"\n",
    "    Given the filenames corresponding to the three images, load and\n",
    "    preprocess them.\n",
    "    \"\"\"\n",
    "    print(\">>> Anchor\", anchor)\n",
    "\n",
    "    return (\n",
    "        personId,\n",
    "        preprocess_image(anchor),\n",
    "        preprocess_image(positive),\n",
    "        preprocess_image(negative),\n",
    "        isGenuine,\n",
    "        anchor_path, positive_path, negative_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****OLD CODE\n",
    "# def triplet_loss(y_true, y_pred):\n",
    "#     alpha = 0.5\n",
    "#     anchor, positive, negative =y_pred[0,0:512], y_pred[0,512:1024], y_pred[0,1024:1536]\n",
    "    \n",
    "#     positive_distance = K.mean(K.square(anchor - positive),axis=-1)\n",
    "#     negative_distance = K.mean(K.square(anchor - negative),axis=-1)\n",
    "#     return K.mean(K.maximum(0.0, positive_distance - negative_distance + alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****OLD CODE\n",
    "\n",
    "# def getImage(basePath, typeOfData, dfRec, imageDimensions):\n",
    "#     img_path = basePath + \"/\" + typeOfData + \"/\" + dfRec[\"relPath\"] + \"/\" + dfRec[\"fileName\"]\n",
    "#     img = cv2.imread(img_path)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = cv2.resize(img, (imageDimensions[1],imageDimensions[0]), interpolation=cv2.INTER_CUBIC)\n",
    "#     #img = img/255 - resulted in a drop in accuracy\n",
    "#     #preprocess_input(img)\n",
    "#     return img;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(images_dataset):\n",
    "    \"\"\"Visualize a few triplets from the supplied batches.\"\"\"\n",
    "\n",
    "    def showImages(ax, image):\n",
    "        for i in range(3):\n",
    "            ax[i].imshow(image[i])\n",
    "            ax[i].get_xaxis().set_visible(False)\n",
    "            ax[i].get_yaxis().set_visible(False)\n",
    "\n",
    "    rows = len(images_dataset)\n",
    "    images = list(images_dataset.as_numpy_iterator())\n",
    "    fig, axs = plt.subplots(rows,3, sharex=True, sharey=True, figsize=(500,500))\n",
    "    for x in range(rows):\n",
    "         anchor, positive, negative = images[x][0],images[x][1],images[x][2]\n",
    "         showImages(axs[x], (anchor, positive, negative))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Load training and test data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       company  personId person        fileName   relPath  Genuine  forged\n",
      "0    Acme Corp         1   Erin      001_01.PNG       001        1       0\n",
      "887  Acme Corp         1   Erin  0119001_01.png  001_forg        0       1\n",
      "894  Acme Corp         1   Erin  0201001_04.png  001_forg        0       1\n",
      "888  Acme Corp         1   Erin  0119001_02.png  001_forg        0       1\n",
      "889  Acme Corp         1   Erin  0119001_03.png  001_forg        0       1\n",
      "(1649, 7)\n"
     ]
    }
   ],
   "source": [
    "basePath = \"/notebooks/capstone/dataset/dataset2/sign_data\"\n",
    "data_train = pd.read_csv(basePath + \"/train/train_clean.csv\")\n",
    "data_train.sort_values(by=\"personId\", inplace=True)\n",
    "print(data_train.head())\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           company  personId person        fileName   relPath  Genuine  forged\n",
      "0    AI Novice Inc        49     IE      01_049.png       049        1       0\n",
      "255  AI Novice Inc        49     IE  02_0114049.PNG  049_forg        0       1\n",
      "256  AI Novice Inc        49     IE  02_0206049.PNG  049_forg        0       1\n",
      "257  AI Novice Inc        49     IE  02_0210049.PNG  049_forg        0       1\n",
      "252  AI Novice Inc        49     IE  01_0114049.PNG  049_forg        0       1\n",
      "258  AI Novice Inc        49     IE  03_0114049.PNG  049_forg        0       1\n",
      "259  AI Novice Inc        49     IE  03_0206049.PNG  049_forg        0       1\n",
      "260  AI Novice Inc        49     IE  03_0210049.PNG  049_forg        0       1\n",
      "261  AI Novice Inc        49     IE  04_0114049.PNG  049_forg        0       1\n",
      "262  AI Novice Inc        49     IE  04_0206049.PNG  049_forg        0       1\n",
      "263  AI Novice Inc        49     IE  04_0210049.PNG  049_forg        0       1\n",
      "254  AI Novice Inc        49     IE  01_0210049.PNG  049_forg        0       1\n",
      "253  AI Novice Inc        49     IE  01_0206049.PNG  049_forg        0       1\n",
      "9    AI Novice Inc        49     IE      10_049.png       049        1       0\n",
      "1    AI Novice Inc        49     IE      02_049.png       049        1       0\n",
      "2    AI Novice Inc        49     IE      03_049.png       049        1       0\n",
      "11   AI Novice Inc        49     IE      12_049.png       049        1       0\n",
      "3    AI Novice Inc        49     IE      04_049.png       049        1       0\n",
      "4    AI Novice Inc        49     IE      05_049.png       049        1       0\n",
      "5    AI Novice Inc        49     IE      06_049.png       049        1       0\n",
      "(500, 7)\n"
     ]
    }
   ],
   "source": [
    "data_test = pd.read_csv(basePath + \"/test/test_clean.csv\")\n",
    "data_test.sort_values(by=\"personId\", inplace=True)\n",
    "print(data_test.head(20))\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare training data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizeImages(df, typeOfData):\n",
    "    personIds = df[\"personId\"].unique()\n",
    "    anchor_imgs = []\n",
    "    postive_imgs = []\n",
    "    negative_imgs = []\n",
    "    for p in personIds:\n",
    "        genuine = df[(df.personId==p) & (df.Genuine==1)]\n",
    "        forg = df[(df.personId==p) & (df.Genuine==0)]\n",
    "        anchor_img = basePath+\"/\"+typeOfData+\"/\"+genuine.iloc[0].relPath + \"/\"+genuine.iloc[0].fileName  \n",
    "        for g in genuine[1:].index:\n",
    "            pos_img= basePath+\"/\"+typeOfData+\"/\"+genuine.loc[g].relPath + \"/\"+genuine.loc[g].fileName  \n",
    "            for f in forg.index:\n",
    "                neg_img =  basePath+\"/\"+typeOfData+\"/\"+forg.loc[f].relPath + \"/\"+forg.loc[f].fileName  \n",
    "                anchor_imgs.append(anchor_img)\n",
    "                postive_imgs.append(pos_img)\n",
    "                negative_imgs.append(neg_img)\n",
    "    \n",
    "    return anchor_imgs,postive_imgs,negative_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images,positive_images,negative_images = categorizeImages(data_train, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Anchor Tensor(\"args_0:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "anchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n",
    "positive_dataset  = tf.data.Dataset.from_tensor_slices(positive_images)\n",
    "negative_dataset  = tf.data.Dataset.from_tensor_slices(negative_images)\n",
    "dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n",
    "dataset = dataset.shuffle(buffer_size=1024)\n",
    "dataset = dataset.map(preprocess_triplets_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split our dataset in train and validation.\n",
    "image_count = len(anchor_dataset)\n",
    "train_dataset = dataset.take(round(image_count * 0.8))\n",
    "val_dataset = dataset.skip(round(image_count * 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize(train_dataset.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(32, drop_remainder=False)\n",
    "train_dataset = train_dataset.prefetch(8)\n",
    "\n",
    "val_dataset = val_dataset.batch(32, drop_remainder=False)\n",
    "val_dataset = val_dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Define Evaluation Functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare each positive each positive in the set and and each negative against all other positives\n",
    "def categorizeTestImages(df, typeOfData):\n",
    "    personIds = df[\"personId\"].unique()\n",
    "    anchor_imgs = []\n",
    "    postive_imgs = []\n",
    "    toCompare_imgs = []\n",
    "    isGenuine = []\n",
    "    personId = []\n",
    "    for p in personIds:\n",
    "        genuine = df[(df.personId==p) & (df.Genuine==1)]\n",
    "        forg = df[(df.personId==p) & (df.Genuine==0)]\n",
    "        anchor_img = basePath+\"/\"+typeOfData+\"/\"+genuine.iloc[0].relPath + \"/\"+genuine.iloc[0].fileName  \n",
    "        for g in genuine[1:].index:\n",
    "            pos_img= basePath+\"/\"+typeOfData+\"/\"+genuine.loc[g].relPath + \"/\"+genuine.loc[g].fileName  \n",
    "            #Compare this with all forgeries\n",
    "            for f in forg.index:\n",
    "                toCompareImg =  basePath+\"/\"+typeOfData+\"/\"+forg.loc[f].relPath + \"/\"+forg.loc[f].fileName \n",
    "                personId.append(p)\n",
    "                anchor_imgs.append(anchor_img)\n",
    "                postive_imgs.append(pos_img)\n",
    "                toCompare_imgs.append(toCompareImg)\n",
    "                isGenuine.append(False)\n",
    "                \n",
    "            # Compare current postive with all other positives besides the anchor\n",
    "            for f in genuine[1:].index:\n",
    "                toCompareImg =  basePath+\"/\"+typeOfData+\"/\"+genuine.loc[f].relPath + \"/\"+genuine.loc[f].fileName  \n",
    "                if ( pos_img != toCompareImg):\n",
    "                    personId.append(p)\n",
    "                    anchor_imgs.append(anchor_img)\n",
    "                    postive_imgs.append(pos_img)\n",
    "                    toCompare_imgs.append(toCompareImg)\n",
    "                    isGenuine.append(True)    \n",
    "    return personId, anchor_imgs,postive_imgs,toCompare_imgs, isGenuine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** OLD CODE **\n",
    "# tst_personId, tst_anchor_images,tst_positive_images,tst_toCompare_imgs, tst_isGenuine = categorizeTestImages(data_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** OLD CODE **\n",
    "# print(len(tst_personId))\n",
    "# print(len(tst_anchor_images))\n",
    "# print(len(tst_positive_images))\n",
    "# print(len(tst_toCompare_imgs))\n",
    "# print(len(tst_isGenuine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** OLD CODE **\n",
    "# tst_personId_dataset = tf.data.Dataset.from_tensor_slices(tst_personId)\n",
    "# tst_anchor_dataset = tf.data.Dataset.from_tensor_slices(tst_anchor_images)\n",
    "# tst_positive_dataset  = tf.data.Dataset.from_tensor_slices(tst_positive_images)\n",
    "# tst_toCompare_imgs_dataset  = tf.data.Dataset.from_tensor_slices(tst_toCompare_imgs)\n",
    "# tst_isGenuine_dataset  = tf.data.Dataset.from_tensor_slices(tst_isGenuine)\n",
    "\n",
    "# tst_anchor_path_dataset = tf.data.Dataset.from_tensor_slices(tst_anchor_images)\n",
    "# tst_positive_path_dataset  = tf.data.Dataset.from_tensor_slices(tst_positive_images)\n",
    "# tst_toCompare_imgs_path_dataset  = tf.data.Dataset.from_tensor_slices(tst_toCompare_imgs)\n",
    "\n",
    "# tst_dataset = tf.data.Dataset.zip((tst_personId_dataset, tst_anchor_dataset, tst_positive_dataset, tst_toCompare_imgs_dataset, tst_isGenuine_dataset, tst_anchor_path_dataset, tst_positive_path_dataset, tst_toCompare_imgs_path_dataset))\n",
    "# tst_dataset = tst_dataset.map(preprocess_triplets)\n",
    "# len(tst_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize(tst_dataset.take(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareEvaluationData(data_df, typeOfData):\n",
    "    personId, anchor_images,positive_images,toCompare_imgs, isGenuine = categorizeTestImages(data_df, typeOfData)\n",
    "    personId_dataset = tf.data.Dataset.from_tensor_slices(personId)\n",
    "    anchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n",
    "    positive_dataset  = tf.data.Dataset.from_tensor_slices(positive_images)\n",
    "    toCompare_imgs_dataset  = tf.data.Dataset.from_tensor_slices(toCompare_imgs)\n",
    "    isGenuine_dataset  = tf.data.Dataset.from_tensor_slices(isGenuine)\n",
    "\n",
    "    anchor_path_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n",
    "    positive_path_dataset  = tf.data.Dataset.from_tensor_slices(positive_images)\n",
    "    toCompare_imgs_path_dataset  = tf.data.Dataset.from_tensor_slices(toCompare_imgs)\n",
    "\n",
    "    dataset = tf.data.Dataset.zip((personId_dataset, anchor_dataset, positive_dataset, toCompare_imgs_dataset, isGenuine_dataset, anchor_path_dataset, positive_path_dataset, toCompare_imgs_path_dataset))\n",
    "    ##dataset = dataset.shuffle(buffer_size=1024)\n",
    "    dataset = dataset.map(preprocess_triplets)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare Model Architecture</b>\n",
    "Setting up the embedding generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = resnet.ResNet50(\n",
    "    weights=\"imagenet\", input_shape=imageDimensions, include_top=False\n",
    ")\n",
    "\n",
    "flatten = layers.Flatten()(base_cnn.output)\n",
    "dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "dense1 = layers.BatchNormalization()(dense1)\n",
    "dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n",
    "dense2 = layers.BatchNormalization()(dense2)\n",
    "output = layers.Dense(256)(dense2)\n",
    "\n",
    "embedding = Model(base_cnn.input, output, name=\"Embedding\")\n",
    "\n",
    "trainable = False\n",
    "for layer in base_cnn.layers:\n",
    "#     if layer.name == \"conv5_block1_out\":     ##TODO: Why only this layer?\n",
    "#         trainable = True\n",
    "    layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Embedding\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          51380736    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       batch_normalization_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 75,168,640\n",
      "Trainable params: 51,579,392\n",
      "Non-trainable params: 23,589,248\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Setting up the Siamese Network model</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance between the anchor\n",
    "    embedding and the positive embedding, and the anchor embedding and the\n",
    "    negative embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return (ap_distance, an_distance)\n",
    "\n",
    "\n",
    "anchor_input = layers.Input(name=\"anchor\", shape=imageDimensions)\n",
    "positive_input = layers.Input(name=\"positive\", shape=imageDimensions)\n",
    "negative_input = layers.Input(name=\"negative\", shape=imageDimensions)\n",
    "\n",
    "distances = DistanceLayer()(\n",
    "    embedding(resnet.preprocess_input(anchor_input)),   ##TODO : What is pre-process input do here?\n",
    "    embedding(resnet.preprocess_input(positive_input)),\n",
    "    embedding(resnet.preprocess_input(negative_input)),\n",
    ")\n",
    "\n",
    "siamese_network = Model(\n",
    "    inputs=[anchor_input, positive_input, negative_input], outputs=distances  ##TODO: Not clear what Output does here?\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Train Model - To Generate Embedding </b>\n",
    "<p>We now need to implement a model with custom training loop so we can compute the triplet loss using the three embeddings produced by the Siamese network.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(Model):\n",
    "    \"\"\"The Siamese Network model with a custom training and testing loops.\n",
    "\n",
    "    Computes the triplet loss using the three embeddings produced by the\n",
    "    Siamese Network.\n",
    "\n",
    "    The triplet loss is defined as:\n",
    "       L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, siamese_network, margin=0.5):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape is a context manager that records every operation that\n",
    "        # you do inside. We are using it here to compute the loss so we can get\n",
    "        # the gradients and apply them using the optimizer specified in\n",
    "        # `compile()`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        # Storing the gradients of the loss function with respect to the\n",
    "        # weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        # Let's update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "         \n",
    "    def _compute_loss_sq(self, data):\n",
    "        # The output of the network is a tuple containing the distances\n",
    "        # between the anchor and the positive example, and the anchor and\n",
    "        # the negative example.\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "\n",
    "        # Computing the Triplet Loss by subtracting both distances and\n",
    "        # making sure we don't get a negative value.\n",
    "        loss = ap_distance - an_distance\n",
    "        loss = tf.maximum(loss + self.margin, 0.1)\n",
    "        return loss\n",
    "    \n",
    "#     def _compute_loss_cos(self, data):\n",
    "#         cosine_similarity = metrics.CosineSimilarity()\n",
    "#         sitive_similarity = cosine_similarity(anchor_embedding, positive_embedding)\n",
    "#         print(\"Positive similarity:\", positive_similarity)\n",
    "#         negative_similarity = cosine_similarity(anchor_embedding, negative_embedding)\n",
    "#         print(\"Negative similarity\", negative_similarity)\n",
    "#         loss = tf.math.squared_difference(positive_similarity, negative_similarity)\n",
    "#         loss = tf.maximum(loss + self.margin, 0.0)\n",
    "#         #tf.math.squared_difference\n",
    "#         return loss\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        return self._compute_loss_sq(data)\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "247/247 [==============================] - 240s 928ms/step - loss: 0.1210 - val_loss: 0.0486\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 224s 908ms/step - loss: 0.0963 - val_loss: 0.0425\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 224s 907ms/step - loss: 0.0785 - val_loss: 0.0367\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 225s 912ms/step - loss: 0.0655 - val_loss: 0.0439\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 224s 907ms/step - loss: 0.0556 - val_loss: 0.0321\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 226s 914ms/step - loss: 0.0466 - val_loss: 0.0333\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 225s 913ms/step - loss: 0.0396 - val_loss: 0.0359\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 224s 907ms/step - loss: 0.0342 - val_loss: 0.0319\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 225s 912ms/step - loss: 0.0308 - val_loss: 0.0316\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 227s 918ms/step - loss: 0.0278 - val_loss: 0.0305\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 224s 908ms/step - loss: 0.0248 - val_loss: 0.0336\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 225s 909ms/step - loss: 0.0226 - val_loss: 0.0294\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 224s 906ms/step - loss: 0.0201 - val_loss: 0.0280\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 226s 914ms/step - loss: 0.0192 - val_loss: 0.0257\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 226s 914ms/step - loss: 0.0173 - val_loss: 0.0236\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 225s 909ms/step - loss: 0.0154 - val_loss: 0.0226\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 224s 907ms/step - loss: 0.0144 - val_loss: 0.0262\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 224s 906ms/step - loss: 0.0127 - val_loss: 0.0236\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 224s 908ms/step - loss: 0.0122 - val_loss: 0.0203\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 225s 910ms/step - loss: 0.0107 - val_loss: 0.0204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f671c405780>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=3,\n",
    "                              verbose=1)\n",
    "\n",
    "early_stop=[earlyStopping]\n",
    "siamese_model = SiameseModel(siamese_network)\n",
    "siamese_model.compile(optimizer=optimizers.Adam(0.0000001))\n",
    "siamese_model.fit(train_dataset, epochs=20, validation_data=val_dataset, callbacks=early_stop)\n",
    "\n",
    "#Tuning\n",
    "# Image dimension=448, margin=0.5 epoch 1, norestraining of weights,Adam=0.0001, loss=2.1\n",
    "# Image dimension=224, margin=0.5 epoch 1, norestraining of weights,Adam=0.0001, loss=0.05\n",
    "# Image dimension=224, margin=0.5 epoch 1, norestraining of weights,Adam=0.0001, lossFn=cos, loss=? \n",
    "# Image dimension=224, margin=10 epoch 1, norestraining of weights,Adam=0.0001, loss=0.5\n",
    "# Image dimension=224, margin=0.5 epoch 1, norestraining of weights, Adam=0.00001 instead of 0.0001 loss=?**  0.000001 - 0.0020 - val_loss: 0.0095\n",
    "# Image dimension=112, margin=0.5 epoch 1, norestraining of weights,Adam=0.0001, loss=0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/notebooks/capstone/models/embeddings-res32'\n",
    "filename2 = '/notebooks/capstone/models/siamesenetwork-res32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /notebooks/capstone/models/embeddings-res32/assets\n",
      "INFO:tensorflow:Assets written to: /notebooks/capstone/models/siamesenetwork-res32/assets\n"
     ]
    }
   ],
   "source": [
    "#embedding.save(filename)\n",
    "#siamese_network.save(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network = tf.keras.models.load_model(filename2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train Decision Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddings(row):\n",
    "    personId, anchor, positive, toCcompare, isGenuine, anchor_path, positive_path, toCcompare_path = row\n",
    "    return (\n",
    "        personId.numpy(), \n",
    "        embedding(resnet.preprocess_input(anchor)),\n",
    "        embedding(resnet.preprocess_input(positive)),\n",
    "        embedding(resnet.preprocess_input(toCcompare)),\n",
    "        isGenuine.numpy()\n",
    "        ,anchor_path.numpy()\n",
    "        ,positive_path.numpy()\n",
    "        ,toCcompare_path.numpy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddingDataFrame(data_df, typeOfData):\n",
    "    dataset = prepareEvaluationData(data_df, typeOfData)\n",
    "    dataset = dataset.batch(1, drop_remainder=False)\n",
    "    embedding_data = [getEmbeddings(row) for row in iter(dataset)]\n",
    "    embeddings_data_df = pd.DataFrame(columns=[\"personId\", \"anchor_embedding\", \"positive_embedding\",\"negative_embedding\",\"isGenuine\", \"Anchor_Path\", \"Pos_Path\", \"ToComparePath\"], data=embedding_data)\n",
    "    return embeddings_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareEmbeds_row_cosine (personId, anchor_embedding, positive_embedding, negative_embedding, isGenuine):\n",
    "    cosine_similarity = metrics.CosineSimilarity()\n",
    "\n",
    "    positive_similarity = cosine_similarity(anchor_embedding, positive_embedding)\n",
    "    #print(\"Positive similarity:\", positive_similarity.numpy())\n",
    "\n",
    "    negative_similarity = cosine_similarity(anchor_embedding, negative_embedding)\n",
    "    #print(\"Negative similarity\", negative_similarity.numpy())\n",
    "    return (positive_similarity.numpy(), negative_similarity.numpy(), (positive_similarity.numpy() - negative_similarity.numpy()))\n",
    "\n",
    "def compareEmbeds_row_kMeansdistance (personId, anchor_embedding, positive_embedding, negative_embedding, isGenuine):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor_embedding - positive_embedding), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor_embedding - negative_embedding), -1)\n",
    "        return (ap_distance, an_distance, (ap_distance-an_distance))\n",
    "\n",
    "def compareEmbeds(df):\n",
    "    df2 = df.apply(lambda row: compareEmbeds_row_kMeansdistance(row.personId, row.anchor_embedding, row.positive_embedding, row.negative_embedding, row.isGenuine), axis=1,  result_type='expand')\n",
    "    df2.columns = [\"Pos\", \"Neg\", \"Diff\"]\n",
    "\n",
    "    df[[\"Pos\", \"Neg\", \"Diff\"]]=df2[[\"Pos\", \"Neg\", \"Diff\"]]\n",
    "    df[\"personId\"]=df[\"personId\"].apply(lambda x: x[0])\n",
    "    df[\"isGenuine\"]=df[\"isGenuine\"].apply(lambda x: x[0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "##Load model\n",
    "embedding = tf.keras.models.load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings_data_df_train = getEmbeddingDataFrame(data_train, \"train\")\n",
    "embeddings_data_df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#pFile_embeddings_train = \"/notebooks/capstone/train_embeddings.pickle\"  ##cosine\n",
    "pFile_embeddings_train = \"/notebooks/capstone/train_embeddings_k.pickle\"  ##kmean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pFile_embeddings_train, 'wb') as file:\n",
    "    pickle.dump(embeddings_data_df_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20798, 8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(pFile_embeddings_train, 'rb') as file:\n",
    "    df = pickle.load(file)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>anchor_embedding</th>\n",
       "      <th>positive_embedding</th>\n",
       "      <th>negative_embedding</th>\n",
       "      <th>isGenuine</th>\n",
       "      <th>Anchor_Path</th>\n",
       "      <th>Pos_Path</th>\n",
       "      <th>ToComparePath</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.5121779, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.5782136, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.61071765, shape=(), dtype=float3...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(1.8254158, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(3.9730136, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-2.1475978, shape=(), dtype=float32))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.5121779, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.5782136, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.5373855, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(1.8254158, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(4.8498363, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-3.0244205, shape=(), dtype=float32))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.5121779, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.5782136, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.6378917, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(1.8254158, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(3.3919668, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-1.566551, shape=(), dtype=float32))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personId                                   anchor_embedding  \\\n",
       "0         1  ((tf.Tensor(0.5121779, shape=(), dtype=float32...   \n",
       "1         1  ((tf.Tensor(0.5121779, shape=(), dtype=float32...   \n",
       "2         1  ((tf.Tensor(0.5121779, shape=(), dtype=float32...   \n",
       "\n",
       "                                  positive_embedding  \\\n",
       "0  ((tf.Tensor(0.5782136, shape=(), dtype=float32...   \n",
       "1  ((tf.Tensor(0.5782136, shape=(), dtype=float32...   \n",
       "2  ((tf.Tensor(0.5782136, shape=(), dtype=float32...   \n",
       "\n",
       "                                  negative_embedding  isGenuine  \\\n",
       "0  ((tf.Tensor(0.61071765, shape=(), dtype=float3...      False   \n",
       "1  ((tf.Tensor(0.5373855, shape=(), dtype=float32...      False   \n",
       "2  ((tf.Tensor(0.6378917, shape=(), dtype=float32...      False   \n",
       "\n",
       "                                         Anchor_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                            Pos_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                       ToComparePath  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                               Pos  \\\n",
       "0  (tf.Tensor(1.8254158, shape=(), dtype=float32))   \n",
       "1  (tf.Tensor(1.8254158, shape=(), dtype=float32))   \n",
       "2  (tf.Tensor(1.8254158, shape=(), dtype=float32))   \n",
       "\n",
       "                                               Neg  \\\n",
       "0  (tf.Tensor(3.9730136, shape=(), dtype=float32))   \n",
       "1  (tf.Tensor(4.8498363, shape=(), dtype=float32))   \n",
       "2  (tf.Tensor(3.3919668, shape=(), dtype=float32))   \n",
       "\n",
       "                                               Diff  \n",
       "0  (tf.Tensor(-2.1475978, shape=(), dtype=float32))  \n",
       "1  (tf.Tensor(-3.0244205, shape=(), dtype=float32))  \n",
       "2   (tf.Tensor(-1.566551, shape=(), dtype=float32))  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare embedding with the anchor\n",
    "df = compareEmbeds(df)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-a279ba40b850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Setup a logistic regression model for predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"personId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pos\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Neg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"isGenuine\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup a logistic regression model for predictions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=0).fit(df[[\"personId\", \"Pos\", \"Neg\"]], df[\"isGenuine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pFile_lrmodel = \"/notebooks/capstone/train_embeddings.pickle\" #cosine\n",
    "pFile_lrmodel = \"/notebooks/capstone/train_embeddings_k.pickle\"  #kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pFile_lrmodel, 'wb') as file:\n",
    "    pickle.dump(lr, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pFile_lrmodel, 'rb') as file:\n",
    "    lr = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = lr.predict(df[[\"personId\", \"Pos\", \"Neg\"]])  #neg = tocompare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:951: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(df[\"isGenuine\"], y_train_predict, pos_label=2)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8716,  1126],\n",
       "       [  716, 10240]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(df[\"isGenuine\"], y_train_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Testing</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting what the network has learned\n",
    "At this point, we can check how the network learned to separate the embeddings depending on whether they belong to similar images.\n",
    "\n",
    "We can use cosine similarity to measure the similarity between embeddings.\n",
    "\n",
    "Let's pick a sample from the dataset to check the similarity between the embeddings generated for each image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compute the cosine similarity between the anchor and positive images and compare it with the similarity between the anchor and the negative images.\n",
    "\n",
    "We should expect the similarity between the anchor and positive images to be larger than the similarity between the anchor and the negative images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Anchor Tensor(\"args_1:0\", shape=(), dtype=string)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>anchor_embedding</th>\n",
       "      <th>positive_embedding</th>\n",
       "      <th>negative_embedding</th>\n",
       "      <th>isGenuine</th>\n",
       "      <th>Anchor_Path</th>\n",
       "      <th>Pos_Path</th>\n",
       "      <th>ToComparePath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[49]</td>\n",
       "      <td>((tf.Tensor(0.5426802, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531887, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.6553408, shape=(), dtype=float32...</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  personId                                   anchor_embedding  \\\n",
       "0     [49]  ((tf.Tensor(0.5426802, shape=(), dtype=float32...   \n",
       "\n",
       "                                  positive_embedding  \\\n",
       "0  ((tf.Tensor(0.42531887, shape=(), dtype=float3...   \n",
       "\n",
       "                                  negative_embedding isGenuine  \\\n",
       "0  ((tf.Tensor(0.6553408, shape=(), dtype=float32...   [False]   \n",
       "\n",
       "                                         Anchor_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                            Pos_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                       ToComparePath  \n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_data_df_tst = getEmbeddingDataFrame(data_test, \"test\")\n",
    "embeddings_data_df_tst.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pFile_embeddings_tst = \"/notebooks/capstone/tst_embeddings_k.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(pFile_embeddings_tst, 'wb') as file:\n",
    "    pickle.dump(embeddings_data_df_tst, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5038, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(pFile_embeddings_tst, 'rb') as file:\n",
    "    df_tst = pickle.load(file)\n",
    "df_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>anchor_embedding</th>\n",
       "      <th>positive_embedding</th>\n",
       "      <th>negative_embedding</th>\n",
       "      <th>isGenuine</th>\n",
       "      <th>Anchor_Path</th>\n",
       "      <th>Pos_Path</th>\n",
       "      <th>ToComparePath</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426802, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531887, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.6553408, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(1.3991302, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(11.180908, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-9.781778, shape=(), dtype=float32))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426802, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531887, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.7207364, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(1.3991302, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(1.7702737, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-0.37114346, shape=(), dtype=float32))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426802, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531887, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.5897555, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(1.3991302, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(5.0825996, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-3.6834693, shape=(), dtype=float32))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personId                                   anchor_embedding  \\\n",
       "0        49  ((tf.Tensor(0.5426802, shape=(), dtype=float32...   \n",
       "1        49  ((tf.Tensor(0.5426802, shape=(), dtype=float32...   \n",
       "2        49  ((tf.Tensor(0.5426802, shape=(), dtype=float32...   \n",
       "\n",
       "                                  positive_embedding  \\\n",
       "0  ((tf.Tensor(0.42531887, shape=(), dtype=float3...   \n",
       "1  ((tf.Tensor(0.42531887, shape=(), dtype=float3...   \n",
       "2  ((tf.Tensor(0.42531887, shape=(), dtype=float3...   \n",
       "\n",
       "                                  negative_embedding  isGenuine  \\\n",
       "0  ((tf.Tensor(0.6553408, shape=(), dtype=float32...      False   \n",
       "1  ((tf.Tensor(0.7207364, shape=(), dtype=float32...      False   \n",
       "2  ((tf.Tensor(0.5897555, shape=(), dtype=float32...      False   \n",
       "\n",
       "                                         Anchor_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                            Pos_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                       ToComparePath  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                               Pos  \\\n",
       "0  (tf.Tensor(1.3991302, shape=(), dtype=float32))   \n",
       "1  (tf.Tensor(1.3991302, shape=(), dtype=float32))   \n",
       "2  (tf.Tensor(1.3991302, shape=(), dtype=float32))   \n",
       "\n",
       "                                               Neg  \\\n",
       "0  (tf.Tensor(11.180908, shape=(), dtype=float32))   \n",
       "1  (tf.Tensor(1.7702737, shape=(), dtype=float32))   \n",
       "2  (tf.Tensor(5.0825996, shape=(), dtype=float32))   \n",
       "\n",
       "                                                Diff  \n",
       "0    (tf.Tensor(-9.781778, shape=(), dtype=float32))  \n",
       "1  (tf.Tensor(-0.37114346, shape=(), dtype=float32))  \n",
       "2   (tf.Tensor(-3.6834693, shape=(), dtype=float32))  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tst = compareEmbeds(df_tst)\n",
    "df_tst.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tst_predict = lr.predict(df_tst[[\"personId\", \"Pos\", \"Neg\"]])  #neg = tocompare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:951: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr_tst, tpr_tst, thresholds_tst = metrics.roc_curve(df_tst[\"isGenuine\"], y_tst_predict, pos_label=2)\n",
    "metrics.auc(fpr_tst, tpr_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2254,  474],\n",
       "       [ 214, 2096]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(df_tst[\"isGenuine\"], y_tst_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(df_tst[[\"personId\", \"Pos\", \"Neg\"]],y_tst_predict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of unknown and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-303cfa3c7c87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"personId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pos\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Neg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tst_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1778\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1780\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1781\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1465\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1275\u001b[0m                          str(average_options))\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 93\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of unknown and binary targets"
     ]
    }
   ],
   "source": [
    "metrics.recall_score(df_tst[[\"personId\", \"Pos\", \"Neg\"]],y_tst_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Old code to remove </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_dataset = tst_dataset.batch(1, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None,), (None, 224, 224, 3), (None, 224, 224, 3), (None, 224, 224, 3), (None,), (None,), (None,), (None,)), types: (tf.int32, tf.float32, tf.float32, tf.float32, tf.bool, tf.string, tf.string, tf.string)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PersonId: [49] anchor: 1 positive: 1 toCompare: 1 isGenuine [False]\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(tst_dataset))\n",
    "personId, anchor, positive, toCompare, isGenuine, anchor_path, positive_path, toCompare_path = sample\n",
    "print(f\"PersonId: %s anchor: %d positive: %d toCompare: %d isGenuine %s\" % (personId.numpy(), len(anchor), len(positive), len(toCompare),isGenuine.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_embedding, positive_embedding, negative_embedding = (\n",
    "    embedding(resnet.preprocess_input(anchor)),\n",
    "    embedding(resnet.preprocess_input(positive)),\n",
    "    embedding(resnet.preprocess_input(toCompare))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PersonId: 1 anchor: 1 positive: 1 toCompare: 1 isGenuine 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"PersonId: %d anchor: %d positive: %d toCompare: %d isGenuine %d\" % (len(personId), len(anchor), len(positive), len(toCompare),len(isGenuine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compute the cosine similarity between the anchor and positive images and compare it with the similarity between the anchor and the negative images.\n",
    "\n",
    "We should expect the similarity between the anchor and positive images to be larger than the similarity between the anchor and the negative images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([49], dtype=int32), 0.99485135, 0.97672117, 0.018130183, array([False]))\n"
     ]
    }
   ],
   "source": [
    "print (compareEmbeds(personId,anchor_embedding, positive_embedding, negative_embedding, isGenuine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>anchor_embedding</th>\n",
       "      <th>positive_embedding</th>\n",
       "      <th>negative_embedding</th>\n",
       "      <th>isGenuine</th>\n",
       "      <th>Anchor_Path</th>\n",
       "      <th>Pos_Path</th>\n",
       "      <th>ToComparePath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[49]</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.6553377, shape=(), dtype=float32...</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  personId                                   anchor_embedding  \\\n",
       "0     [49]  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "\n",
       "                                  positive_embedding  \\\n",
       "0  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "\n",
       "                                  negative_embedding isGenuine  \\\n",
       "0  ((tf.Tensor(0.6553377, shape=(), dtype=float32...   [False]   \n",
       "\n",
       "                                         Anchor_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                            Pos_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                       ToComparePath  \n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save the embeddings\n",
    "tst_embedding_data = [getEmbeddings(row) for row in iter(tst_dataset)]\n",
    "tst_data_embeddings_df = pd.DataFrame(columns=[\"personId\", \"anchor_embedding\", \"positive_embedding\",\"negative_embedding\",\"isGenuine\", \"Anchor_Path\", \"Pos_Path\", \"ToComparePath\"], data=tst_embedding_data)\n",
    "tst_data_embeddings_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pFile_embeddings = \"/notebooks/capstone/results_embeddings.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pFile_embeddings, 'wb') as file:\n",
    "    pickle.dump(tst_data_embeddings_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5038, 8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(pFile_embeddings, 'rb') as file:\n",
    "    df = pickle.load(file)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['personId', 'anchor_embedding', 'positive_embedding',\n",
       "       'negative_embedding', 'isGenuine', 'Anchor_Path', 'Pos_Path',\n",
       "       'ToComparePath'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Approach 1</b>: Compare the relative distance of positive and negative related to Anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.976721</td>\n",
       "      <td>0.018130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.994128</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.987881</td>\n",
       "      <td>0.006971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pos       Neg      Diff\n",
       "0  0.994851  0.976721  0.018130\n",
       "1  0.994851  0.994128  0.000723\n",
       "2  0.994851  0.987881  0.006971"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.apply(lambda row: compareEmbeds(row.personId, row.anchor_embedding, row.positive_embedding, row.negative_embedding, row.isGenuine), axis=1,  result_type='expand')\n",
    "df2.columns = [\"Pos\", \"Neg\", \"Diff\"]\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>anchor_embedding</th>\n",
       "      <th>positive_embedding</th>\n",
       "      <th>negative_embedding</th>\n",
       "      <th>isGenuine</th>\n",
       "      <th>Anchor_Path</th>\n",
       "      <th>Pos_Path</th>\n",
       "      <th>ToComparePath</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.6553377, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.976721</td>\n",
       "      <td>0.018130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.7207349, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.994128</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.58976376, shape=(), dtype=float3...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.987881</td>\n",
       "      <td>0.006971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personId                                   anchor_embedding  \\\n",
       "0        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "1        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "2        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "\n",
       "                                  positive_embedding  \\\n",
       "0  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "1  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "2  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "\n",
       "                                  negative_embedding  isGenuine  \\\n",
       "0  ((tf.Tensor(0.6553377, shape=(), dtype=float32...      False   \n",
       "1  ((tf.Tensor(0.7207349, shape=(), dtype=float32...      False   \n",
       "2  ((tf.Tensor(0.58976376, shape=(), dtype=float3...      False   \n",
       "\n",
       "                                         Anchor_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                            Pos_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                       ToComparePath       Pos       Neg  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.976721   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.994128   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.987881   \n",
       "\n",
       "       Diff  \n",
       "0  0.018130  \n",
       "1  0.000723  \n",
       "2  0.006971  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Pos\", \"Neg\", \"Diff\"]]=df2[[\"Pos\", \"Neg\", \"Diff\"]]\n",
    "df[\"personId\"]=df[\"personId\"].apply(lambda x: x[0])\n",
    "df[\"isGenuine\"]=df[\"isGenuine\"].apply(lambda x: x[0])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pFile = \"/notebooks/capstone/results_approach1.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pFile, 'wb') as file:\n",
    "     pickle.dump(df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>anchor_embedding</th>\n",
       "      <th>positive_embedding</th>\n",
       "      <th>negative_embedding</th>\n",
       "      <th>isGenuine</th>\n",
       "      <th>Anchor_Path</th>\n",
       "      <th>Pos_Path</th>\n",
       "      <th>ToComparePath</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.6553377, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.976721</td>\n",
       "      <td>0.018130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.7207349, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.994128</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.58976376, shape=(), dtype=float3...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.987881</td>\n",
       "      <td>0.006971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.74497586, shape=(), dtype=float3...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.981951</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.50403637, shape=(), dtype=float3...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.981849</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personId                                   anchor_embedding  \\\n",
       "0        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "1        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "2        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "3        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "4        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "\n",
       "                                  positive_embedding  \\\n",
       "0  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "1  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "2  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "3  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "4  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "\n",
       "                                  negative_embedding  isGenuine  \\\n",
       "0  ((tf.Tensor(0.6553377, shape=(), dtype=float32...      False   \n",
       "1  ((tf.Tensor(0.7207349, shape=(), dtype=float32...      False   \n",
       "2  ((tf.Tensor(0.58976376, shape=(), dtype=float3...      False   \n",
       "3  ((tf.Tensor(0.74497586, shape=(), dtype=float3...      False   \n",
       "4  ((tf.Tensor(0.50403637, shape=(), dtype=float3...      False   \n",
       "\n",
       "                                         Anchor_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "3  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "4  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                            Pos_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "3  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "4  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                       ToComparePath       Pos       Neg  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.976721   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.994128   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.987881   \n",
       "3  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.981951   \n",
       "4  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.981849   \n",
       "\n",
       "       Diff  \n",
       "0  0.018130  \n",
       "1  0.000723  \n",
       "2  0.006971  \n",
       "3  0.012900  \n",
       "4  0.013002  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(pFile, 'rb') as file:\n",
    "     df = pickle.load(file)\n",
    "\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>anchor_embedding</th>\n",
       "      <th>positive_embedding</th>\n",
       "      <th>negative_embedding</th>\n",
       "      <th>isGenuine</th>\n",
       "      <th>Anchor_Path</th>\n",
       "      <th>Pos_Path</th>\n",
       "      <th>ToComparePath</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.6553377, shape=(), dtype=float32...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.976721</td>\n",
       "      <td>0.018130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.7207349, shape=(), dtype=float32...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.994128</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.58976376, shape=(), dtype=float3...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.987881</td>\n",
       "      <td>0.006971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.74497586, shape=(), dtype=float3...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.981951</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.50403637, shape=(), dtype=float3...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.981849</td>\n",
       "      <td>0.013002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personId                                   anchor_embedding  \\\n",
       "0        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "1        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "2        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "3        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "4        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "\n",
       "                                  positive_embedding  \\\n",
       "0  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "1  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "2  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "3  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "4  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "\n",
       "                                  negative_embedding  isGenuine  \\\n",
       "0  ((tf.Tensor(0.6553377, shape=(), dtype=float32...          0   \n",
       "1  ((tf.Tensor(0.7207349, shape=(), dtype=float32...          0   \n",
       "2  ((tf.Tensor(0.58976376, shape=(), dtype=float3...          0   \n",
       "3  ((tf.Tensor(0.74497586, shape=(), dtype=float3...          0   \n",
       "4  ((tf.Tensor(0.50403637, shape=(), dtype=float3...          0   \n",
       "\n",
       "                                         Anchor_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "3  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "4  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                            Pos_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "3  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "4  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                       ToComparePath       Pos       Neg  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.976721   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.994128   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.987881   \n",
       "3  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.981951   \n",
       "4  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.981849   \n",
       "\n",
       "       Diff  \n",
       "0  0.018130  \n",
       "1  0.000723  \n",
       "2  0.006971  \n",
       "3  0.012900  \n",
       "4  0.013002  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"isGenuine\"] = df[\"isGenuine\"].map(lambda x: 1 if x else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diff</th>\n",
       "      <th>isGenuine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.181302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007232</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069706</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.129004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.130024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Diff  isGenuine\n",
       "0  0.181302          0\n",
       "1  0.007232          0\n",
       "2  0.069706          0\n",
       "3  0.129004          0\n",
       "4  0.130024          0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[[\"Diff\",\"isGenuine\"]]\n",
    "df2[\"Diff\"] = df2[\"Diff\"]*10\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_f = df2[(df2.isGenuine == 0)]  # & (df2.Diff < threshold)\n",
    "df3_g = df2[(df2.isGenuine == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diff</th>\n",
       "      <th>isGenuine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.004438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.000964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.005600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.000856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.005271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Diff  isGenuine\n",
       "12 -0.004438          1\n",
       "13 -0.000964          1\n",
       "14  0.005600          1\n",
       "15 -0.000856          1\n",
       "16  0.005271          1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.,  38., 120., 347., 648., 648., 347., 120.,  38.,   2.]),\n",
       " array([-0.03617704, -0.02894163, -0.02170622, -0.01447082, -0.00723541,\n",
       "         0.        ,  0.00723541,  0.01447082,  0.02170622,  0.02894163,\n",
       "         0.03617704]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold = 0.01\n",
    "\n",
    "df4_f = df3_f.copy(deep=True)\n",
    "df4_f[\"Diff\"] = df4_f[\"Diff\"].map(lambda x: x if  x < threshold else threshold)\n",
    "\n",
    "plt.figure(figsize=(20, 3))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.title('Forgery')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Total Count: \" + str(len(df4_f)) + \"# below threshold: \" + str(len(df3_f[df4_f.Diff < threshold ])))\n",
    "plt.hist(df4_f[\"Diff\"])\n",
    "\n",
    "# df3_g = df2[df2.isGenuine==1][\"Diff\"]*10  #*0.0001\n",
    "# df4_g = [(d if d < threshold else threshold) for d in df3_g]#0.0000006]\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.title('Genuine')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Total Count: \" + str(len(df3_g)) + \"# above threshold: \" + str(len(df3_g[df3_g.Diff > threshold ])))\n",
    "plt.hist(df3_g[\"Diff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diff</th>\n",
       "      <th>isGenuine</th>\n",
       "      <th>Forgery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diff</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.570392</td>\n",
       "      <td>0.570392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isGenuine</th>\n",
       "      <td>-0.570392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forgery</th>\n",
       "      <td>0.570392</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Diff  isGenuine   Forgery\n",
       "Diff       1.000000  -0.570392  0.570392\n",
       "isGenuine -0.570392   1.000000 -1.000000\n",
       "Forgery    0.570392  -1.000000  1.000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"Forgery\"] =  [1 if d==0 else 0 for d in df2[\"isGenuine\"].values]\n",
    "df2.corr() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>anchor_embedding</th>\n",
       "      <th>positive_embedding</th>\n",
       "      <th>negative_embedding</th>\n",
       "      <th>isGenuine</th>\n",
       "      <th>Anchor_Path</th>\n",
       "      <th>Pos_Path</th>\n",
       "      <th>ToComparePath</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.6271175, shape=(), dtype=float32...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.995038</td>\n",
       "      <td>-0.000187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.4241791, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.6271175, shape=(), dtype=float32...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.995044</td>\n",
       "      <td>0.995135</td>\n",
       "      <td>-0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.55992514, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.6198189, shape=(), dtype=float32...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.993731</td>\n",
       "      <td>0.994099</td>\n",
       "      <td>-0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.55992514, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.6271175, shape=(), dtype=float32...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.993731</td>\n",
       "      <td>0.994478</td>\n",
       "      <td>-0.000747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.55992514, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.65422386, shape=(), dtype=float3...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.993731</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>-0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.46478623, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.6271175, shape=(), dtype=float32...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.995023</td>\n",
       "      <td>0.995124</td>\n",
       "      <td>-0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.47805738, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.6198189, shape=(), dtype=float32...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.993797</td>\n",
       "      <td>0.994132</td>\n",
       "      <td>-0.000334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.47805738, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.6271175, shape=(), dtype=float32...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.993797</td>\n",
       "      <td>0.994511</td>\n",
       "      <td>-0.000714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.47805738, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.65422386, shape=(), dtype=float3...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.993797</td>\n",
       "      <td>0.994286</td>\n",
       "      <td>-0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.5123288, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.7207349, shape=(), dtype=float32...</td>\n",
       "      <td>0</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>0.993347</td>\n",
       "      <td>-0.000058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     personId                                   anchor_embedding  \\\n",
       "8          49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "52         49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "71         49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "74         49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "77         49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "96         49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "115        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "118        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "121        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "155        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "\n",
       "                                    positive_embedding  \\\n",
       "8    ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "52   ((tf.Tensor(0.4241791, shape=(), dtype=float32...   \n",
       "71   ((tf.Tensor(0.55992514, shape=(), dtype=float3...   \n",
       "74   ((tf.Tensor(0.55992514, shape=(), dtype=float3...   \n",
       "77   ((tf.Tensor(0.55992514, shape=(), dtype=float3...   \n",
       "96   ((tf.Tensor(0.46478623, shape=(), dtype=float3...   \n",
       "115  ((tf.Tensor(0.47805738, shape=(), dtype=float3...   \n",
       "118  ((tf.Tensor(0.47805738, shape=(), dtype=float3...   \n",
       "121  ((tf.Tensor(0.47805738, shape=(), dtype=float3...   \n",
       "155  ((tf.Tensor(0.5123288, shape=(), dtype=float32...   \n",
       "\n",
       "                                    negative_embedding  isGenuine  \\\n",
       "8    ((tf.Tensor(0.6271175, shape=(), dtype=float32...          0   \n",
       "52   ((tf.Tensor(0.6271175, shape=(), dtype=float32...          0   \n",
       "71   ((tf.Tensor(0.6198189, shape=(), dtype=float32...          0   \n",
       "74   ((tf.Tensor(0.6271175, shape=(), dtype=float32...          0   \n",
       "77   ((tf.Tensor(0.65422386, shape=(), dtype=float3...          0   \n",
       "96   ((tf.Tensor(0.6271175, shape=(), dtype=float32...          0   \n",
       "115  ((tf.Tensor(0.6198189, shape=(), dtype=float32...          0   \n",
       "118  ((tf.Tensor(0.6271175, shape=(), dtype=float32...          0   \n",
       "121  ((tf.Tensor(0.65422386, shape=(), dtype=float3...          0   \n",
       "155  ((tf.Tensor(0.7207349, shape=(), dtype=float32...          0   \n",
       "\n",
       "                                           Anchor_Path  \\\n",
       "8    [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "52   [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "71   [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "74   [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "77   [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "96   [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "115  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "118  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "121  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "155  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                              Pos_Path  \\\n",
       "8    [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "52   [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "71   [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "74   [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "77   [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "96   [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "115  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "118  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "121  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "155  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                         ToComparePath       Pos       Neg  \\\n",
       "8    [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.995038   \n",
       "52   [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.995044  0.995135   \n",
       "71   [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.993731  0.994099   \n",
       "74   [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.993731  0.994478   \n",
       "77   [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.993731  0.994253   \n",
       "96   [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.995023  0.995124   \n",
       "115  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.993797  0.994132   \n",
       "118  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.993797  0.994511   \n",
       "121  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.993797  0.994286   \n",
       "155  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.993289  0.993347   \n",
       "\n",
       "         Diff  \n",
       "8   -0.000187  \n",
       "52  -0.000091  \n",
       "71  -0.000367  \n",
       "74  -0.000747  \n",
       "77  -0.000522  \n",
       "96  -0.000101  \n",
       "115 -0.000334  \n",
       "118 -0.000714  \n",
       "121 -0.000489  \n",
       "155 -0.000058  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All forgeries with a distance < 0\n",
    "df[(df.Diff < 0) & (df.isGenuine ==0)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>anchor_embedding</th>\n",
       "      <th>positive_embedding</th>\n",
       "      <th>negative_embedding</th>\n",
       "      <th>isGenuine</th>\n",
       "      <th>Anchor_Path</th>\n",
       "      <th>Pos_Path</th>\n",
       "      <th>ToComparePath</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.5352584, shape=(), dtype=float32...</td>\n",
       "      <td>1</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.995295</td>\n",
       "      <td>-0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.4241791, shape=(), dtype=float32...</td>\n",
       "      <td>1</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.994948</td>\n",
       "      <td>-0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.46478623, shape=(), dtype=float3...</td>\n",
       "      <td>1</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.994937</td>\n",
       "      <td>-0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.55645454, shape=(), dtype=float3...</td>\n",
       "      <td>1</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.995431</td>\n",
       "      <td>-0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.5111933, shape=(), dtype=float32...</td>\n",
       "      <td>1</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.995569</td>\n",
       "      <td>-0.000718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.42531458, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.53742385, shape=(), dtype=float3...</td>\n",
       "      <td>1</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>0.995127</td>\n",
       "      <td>-0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.5352584, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.55645454, shape=(), dtype=float3...</td>\n",
       "      <td>1</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.995739</td>\n",
       "      <td>0.995875</td>\n",
       "      <td>-0.000136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.5352584, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.5111933, shape=(), dtype=float32...</td>\n",
       "      <td>1</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.995739</td>\n",
       "      <td>0.996013</td>\n",
       "      <td>-0.000274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.4241791, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.5352584, shape=(), dtype=float32...</td>\n",
       "      <td>1</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.995044</td>\n",
       "      <td>0.995392</td>\n",
       "      <td>-0.000347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.5426748, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.4241791, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.55645454, shape=(), dtype=float3...</td>\n",
       "      <td>1</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>0.995044</td>\n",
       "      <td>0.995528</td>\n",
       "      <td>-0.000484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    personId                                   anchor_embedding  \\\n",
       "12        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "13        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "15        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "17        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "19        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "20        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "39        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "41        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "57        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "61        49  ((tf.Tensor(0.5426748, shape=(), dtype=float32...   \n",
       "\n",
       "                                   positive_embedding  \\\n",
       "12  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "13  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "15  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "17  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "19  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "20  ((tf.Tensor(0.42531458, shape=(), dtype=float3...   \n",
       "39  ((tf.Tensor(0.5352584, shape=(), dtype=float32...   \n",
       "41  ((tf.Tensor(0.5352584, shape=(), dtype=float32...   \n",
       "57  ((tf.Tensor(0.4241791, shape=(), dtype=float32...   \n",
       "61  ((tf.Tensor(0.4241791, shape=(), dtype=float32...   \n",
       "\n",
       "                                   negative_embedding  isGenuine  \\\n",
       "12  ((tf.Tensor(0.5352584, shape=(), dtype=float32...          1   \n",
       "13  ((tf.Tensor(0.4241791, shape=(), dtype=float32...          1   \n",
       "15  ((tf.Tensor(0.46478623, shape=(), dtype=float3...          1   \n",
       "17  ((tf.Tensor(0.55645454, shape=(), dtype=float3...          1   \n",
       "19  ((tf.Tensor(0.5111933, shape=(), dtype=float32...          1   \n",
       "20  ((tf.Tensor(0.53742385, shape=(), dtype=float3...          1   \n",
       "39  ((tf.Tensor(0.55645454, shape=(), dtype=float3...          1   \n",
       "41  ((tf.Tensor(0.5111933, shape=(), dtype=float32...          1   \n",
       "57  ((tf.Tensor(0.5352584, shape=(), dtype=float32...          1   \n",
       "61  ((tf.Tensor(0.55645454, shape=(), dtype=float3...          1   \n",
       "\n",
       "                                          Anchor_Path  \\\n",
       "12  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "13  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "15  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "17  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "19  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "20  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "39  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "41  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "57  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "61  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                             Pos_Path  \\\n",
       "12  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "13  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "15  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "17  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "19  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "20  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "39  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "41  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "57  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "61  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                        ToComparePath       Pos       Neg  \\\n",
       "12  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.995295   \n",
       "13  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.994948   \n",
       "15  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.994937   \n",
       "17  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.995431   \n",
       "19  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.995569   \n",
       "20  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.994851  0.995127   \n",
       "39  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.995739  0.995875   \n",
       "41  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.995739  0.996013   \n",
       "57  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.995044  0.995392   \n",
       "61  [b'/notebooks/capstone/dataset/dataset2/sign_d...  0.995044  0.995528   \n",
       "\n",
       "        Diff  \n",
       "12 -0.000444  \n",
       "13 -0.000096  \n",
       "15 -0.000086  \n",
       "17 -0.000580  \n",
       "19 -0.000718  \n",
       "20 -0.000276  \n",
       "39 -0.000136  \n",
       "41 -0.000274  \n",
       "57 -0.000347  \n",
       "61 -0.000484  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All Genuine with a distance < 0\n",
    "df[(df.Diff < 0) & (df.isGenuine ==1)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ToCompare'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ToCompare'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-f6eba073e284>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9925\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf4_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ToCompare\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misGenuine\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ToCompare\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf4_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ToCompare\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf4_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ToCompare\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m  \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ToCompare'"
     ]
    }
   ],
   "source": [
    "threshold = 0.9925\n",
    "\n",
    "df4_f[\"ToCompare\"] = df[df.isGenuine==0][\"ToCompare\"]\n",
    "df4_f[\"ToCompare\"] = df4_f[\"ToCompare\"].map(lambda x: x if  x > threshold else threshold-0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_g = df[(df.isGenuine == 1)]\n",
    "df4_g = df3_g.copy(deep=True)\n",
    "df4_g[\"Pos\"] = df3_g[\"Pos\"].map(lambda x: x if  x > threshold else (threshold-0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 3))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.title('Forgery')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Total Count: \" + str(len(df3_f)) + \"# below threshold: \" + str(len(df3_f[df4_f.ToCompare > threshold ])))\n",
    "plt.hist(df4_f[\"ToCompare\"])\n",
    "\n",
    "# df3_g = df2[df2.isGenuine==1][\"Diff\"]*10  #*0.0001\n",
    "# df4_g = [(d if d < threshold else threshold) for d in df3_g]#0.0000006]\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.title('Genuine')\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Total Count: \" + str(len(df3_g)) + \"# above threshold: \" + str(len(df3_g[df3_g.Pos < threshold ])))\n",
    "plt.hist(df4_g[\"Pos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluation<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
